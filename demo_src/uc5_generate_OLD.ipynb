{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:yellow'><font color=\"blue\">\n",
    "UC5, DEEP IMAGE ANNOTATION\n",
    "</font></span>\n",
    "\n",
    "DeepHealth Project\n",
    "\n",
    "Franco Alberto Cardillo (`francoalberto.cardillo@ilc.cnr.it`)\n",
    "\n",
    "\n",
    "TEXT GENERATION ON the Indiana University Chest X-ray dataset\n",
    "\n",
    "PRE:\n",
    "\n",
    "     - pre-trained CNN module;\n",
    "     - pre-trained (unrolled) RNN module;\n",
    "     - ECVL dataset;\n",
    "     - img <-> text dataset;\n",
    "     - input images.\n",
    "\n",
    "Standalone notebook (the previous files are generated by python modules available on the github project repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import humanize as H\n",
    "from nltk import sent_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import numpy as np\n",
    "from numpy import count_nonzero as nnz\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from posixpath import join\n",
    "import pyecvl.ecvl as ecvl\n",
    "import pyeddl.eddl as eddl\n",
    "from pyeddl.tensor import Tensor, DEV_CPU, DEV_GPU\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I M A G E - R E L A T E D   C L A S S E S   A N D   F U N C T I O N S\n",
    "def get_augmentations_chest_iu(img_size=224):\n",
    "    mean = [0.48197903, 0.48197903, 0.48197903]\n",
    "    std = [0.26261734, 0.26261734, 0.26261734]\n",
    "    \n",
    "    train_augs = ecvl.SequentialAugmentationContainer([\n",
    "                    ecvl.AugResizeDim([300, 300]),\n",
    "                    ecvl.AugRotate([-5,5]),\n",
    "                    ecvl.AugToFloat32(divisor=255.0),\n",
    "                    ecvl.AugNormalize(mean, std),\n",
    "                    ecvl.AugRandomCrop([img_size, img_size])\n",
    "            ])\n",
    "\n",
    "    test_augs =  ecvl.SequentialAugmentationContainer([\n",
    "                        ecvl.AugResizeDim([300, 300]),\n",
    "                        ecvl.AugToFloat32(divisor=255.0),\n",
    "                        ecvl.AugNormalize(mean, std),\n",
    "                        ecvl.AugCenterCrop([img_size, img_size])\n",
    "                    ])\n",
    "    return train_augs, test_augs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T E X T - R E L A T E D   C L A S S E S   A N D   F U N C T I O N S\n",
    "class Vocabulary:\n",
    "    PAD = 0\n",
    "    OOV = 1\n",
    "    BOS = 2\n",
    "    EOS = 3\n",
    "\n",
    "    def __init__(self):\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        self.idx2word = {Vocabulary.PAD: \"<pad>\", Vocabulary.OOV: \"<oov>\", Vocabulary.BOS: \"<bos>\", Vocabulary.EOS: \"<eos>\"}\n",
    "        self.word2idx = {w:i for i,w in self.idx2word.items()}\n",
    "        assert self.word2idx[\"<pad>\"] == 0\n",
    "\n",
    "        self.word2count = {}\n",
    "        self.idx = len(self.idx2word)\n",
    "        self.word_count = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx.keys():\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.word2count[word] = 1\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "        self.word_count += 1\n",
    "    #<\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            if word != \".\":\n",
    "                # commas and other punctuation already removed\n",
    "                self.add_word(word)\n",
    "    #<\n",
    "\n",
    "    def add_text(self, text):\n",
    "        for sentence in sent_tokenize(text):\n",
    "            self.add_sentence(sentence)\n",
    "    #<\n",
    "    \n",
    "    def keep_n_words(self, n_words: int):\n",
    "        n = self.word_count\n",
    "        print(\"(vocabulary) initial word count (total):\", self.word_count)\n",
    "        print(\"(vocabulary) initial number of words:\", len(self.word2count))\n",
    "\n",
    "        wc = list(self.word2count.items())\n",
    "        wc = sorted(wc, key=lambda elem: -elem[1])\n",
    "        # wc does not contain special tokens\n",
    "        keep = wc[:n_words]\n",
    "        rem = wc[n_words:]\n",
    "        self.initialize()\n",
    "        for w, _ in keep:\n",
    "            self.add_word(w)\n",
    "\n",
    "        print(\"(vocabulary) after iterating with add_word number of words:\", len(self.word2count))\n",
    "        assert len(self.word2idx) == n_words+4, f\"words: {len(self.word2count)}, requested: {n_words}+4\"  # number of special tokens\n",
    "        # reset self.word2count\n",
    "        self.word_count = 0\n",
    "        for w, c in keep:\n",
    "            self.word_count += c\n",
    "            self.word2count[w] = c\n",
    "        print(\"(vocabulary) final word_count (total): \", self.word_count)\n",
    "        print(\"(vocabulary) final number of words:\", len(self.word2count))\n",
    "\n",
    "        #print(\"diff:\", n - self.word_count)\n",
    "        #print(\"removed words:\", len(rem))\n",
    "        #print(\"coverage:\", self.word_count / n)\n",
    "\n",
    "    def decode(self, idxs):\n",
    "        return [self.idx2word[i] for i in idxs]\n",
    "#< class Vocabulary\n",
    "\n",
    "\n",
    "#> t e x t   c o l l a t i o n\n",
    "def collate_fn_one_s(enc_text, n_sents=1, max_tokens=12, verbose=False):\n",
    "    assert type(enc_text) is list, f\"expected type 'list', received {type(enc_text)}\"\n",
    "    if verbose: \n",
    "        print(f\"collating_one_s, len {len(enc_text)}:\", enc_text)\n",
    "    \n",
    "    if type(enc_text[0]) is list:\n",
    "        enc_text = enc_text[0]\n",
    "        \n",
    "    bos = Vocabulary.BOS\n",
    "    eos = Vocabulary.EOS\n",
    "    pad = Vocabulary.PAD\n",
    "    \n",
    "    enc_text = [bos] + enc_text + [eos]\n",
    "    l = len(enc_text)\n",
    "    if verbose: print(f\"len with bos and eos: {l}, max is {max_tokens}\")\n",
    "    if l > max_tokens:\n",
    "        if verbose: print(\"truncating\")\n",
    "        enc_text[max_tokens-1] = eos\n",
    "        enc_text = enc_text[:max_tokens]\n",
    "    elif l < max_tokens:\n",
    "        if verbose: print(\"padding\", flush=True)\n",
    "        enc_text += ([pad] * (max_tokens -l) )\n",
    "    \n",
    "    if verbose: print(f\"returning collation ({len(enc_text)}):\", enc_text)\n",
    "    assert len(enc_text) == max_tokens\n",
    "    return np.array(enc_text)\n",
    "#<\n",
    "\n",
    "    \n",
    "def collate_fn_n_sents(enc_text, n_sents, max_tokens, verbose=False):\n",
    "    res = []\n",
    "    for i, enc_sent in enumerate(enc_text):\n",
    "        if i == n_sents:\n",
    "            break\n",
    "        v = collate_fn_one_s(enc_sent, n_sents=1, max_tokens=max_tokens, verbose=verbose)\n",
    "        res.append(v)\n",
    "\n",
    "    if len(res) > n_sents:\n",
    "        res = res[:n_sents]\n",
    "    elif len(res) < n_sents:\n",
    "        padded = [Vocabulary.PAD] * max_tokens\n",
    "        for i in range(n_sents - len(res)):\n",
    "            res.append(np.array(padded))\n",
    "\n",
    "    res = np.array(res)\n",
    "    if verbose: print(f\"collate_fn_n_sents, returning {res.shape}\")\n",
    "    return res\n",
    "#<\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E C V L   D A T A S E T  /  D A T A L O A D E R\n",
    "\n",
    "def load_ecvl_dataset(config):\n",
    "    _, test_augs = get_augmentations_chest_iu(config[\"img_size\"])\n",
    "    augs = ecvl.DatasetAugmentations(augs=[test_augs, test_augs, test_augs])\n",
    "    ecvl.AugmentationParam.SetSeed(config[\"seed\"])\n",
    "    ecvl.DLDataset.SetSplitSeed(config[\"shuffle_seed\"])\n",
    "    print(\"loading dataset:\", config[\"ecvl_ds_fn\"])\n",
    "    \n",
    "    if config[\"eddl_cs\"] == \"cpu\":\n",
    "        num_workers = 16\n",
    "    else:\n",
    "        num_workers = 8 if nnz(config[\"gpu_id\"]) == 1 else 4 * nnz(config[\"gpu_id\"])\n",
    "\n",
    "    print(f\"using num workers = {num_workers}\")\n",
    "    print(\"using batch size:\", config[\"bs\"])\n",
    "    dataset = ecvl.DLDataset(join(config[\"in_fld\"], config[\"ecvl_ds_fn\"]), \n",
    "                        batch_size=config[\"bs\"], \n",
    "                        augs=augs, \n",
    "                        ctype=ecvl.ColorType.RGB, ctype_gt=ecvl.ColorType.GRAY, \n",
    "                        num_workers=num_workers, queue_ratio_size= 4 * nnz(config[\"gpu_id\"]), \n",
    "                        drop_last={\"training\": False, \"validation\": False, \"test\": False}) # drop_last defined in training.augmentations\n",
    "                        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aux functions\n",
    "def configure(\n",
    "        in_fld=\"/opt/uc5/results/demo/text_gen\", \n",
    "        img_fld=\"/mnt/datasets/uc5/std-dataset/image\",\n",
    "        ecvl_ds_fn=\"ecvl_ds.yml\",\n",
    "        bs=128,\n",
    "        n_tokens=12,\n",
    "        eddl_cs_mem=\"mid_mem\", \n",
    "        eddl_cs=\"gpu\", \n",
    "        gpu_id=[1],\n",
    "        cnn_fn=\"best_cnn\",\n",
    "        rnn_fn=\"best_rnn\",\n",
    "        vocab_fn=\"vocab.pkl\",\n",
    "        img_size=224,\n",
    "        seed=1234,\n",
    "        shuffle_seed=5678):\n",
    "    config = locals()\n",
    "    return config\n",
    "#<\n",
    "\n",
    "\n",
    "def get_eddl_cs(config):\n",
    "    return  eddl.CS_GPU(g=config[\"gpu_id\"], mem=config[\"eddl_cs_mem\"]) if config[\"eddl_cs\"] == \"gpu\" else eddl.CS_CPU()\n",
    "#<\n",
    "\n",
    "\n",
    "def load_cnn(config):\n",
    "    cnn_fn = join(config[\"in_fld\"], config[\"cnn_fn\"] + \".onnx\")\n",
    "    cnn = eddl.import_net_from_onnx_file(cnn_fn)\n",
    "    eddl.build(cnn, \n",
    "        eddl.adam(lr=1e-04), # not relevant\n",
    "        [\"binary_cross_entropy\"],  # not relevant\n",
    "        [\"binary_accuracy\"], # not relevant\n",
    "        get_eddl_cs(config) , \n",
    "        init_weights=False)  # losses, metrics\n",
    "    eddl.set_mode(cnn, 0)  # inference\n",
    "    return cnn\n",
    "#<\n",
    "\n",
    "def load_rnn(config):\n",
    "    rnn_fn = join(config[\"in_fld\"], config[\"rnn_fn\"] + \".onnx\")\n",
    "    rnn = eddl.import_net_from_onnx_file(rnn_fn)\n",
    "    eddl.build(rnn, \n",
    "        eddl.adam(lr=1e-04), \n",
    "        [\"binary_cross_entropy\"], \n",
    "        [\"binary_accuracy\"], \n",
    "        get_eddl_cs(config), \n",
    "        init_weights=False)\n",
    "    return rnn\n",
    "#<\n",
    "\n",
    "\n",
    "def load_vocabulary(config):\n",
    "    with open(join(config[\"in_fld\"], config[\"vocab_fn\"]), \"rb\") as f:\n",
    "        vocab = pickle.load(f)\n",
    "    return vocab\n",
    "#<\n",
    "\n",
    "\n",
    "def load_image_text_ds(config):\n",
    "    text_dataset = pd.read_pickle(join(config[\"in_fld\"], \"img_text_dataset.pkl\")).set_index(\"image_filename\")\n",
    "    return text_dataset\n",
    "#<\n",
    "\n",
    "\n",
    "def create_rnn_for_generation(unrolled_rnn, visual_dim, semantic_dim, lstm_dim, n_words, word_emb_dim, config, verbose=False):\n",
    "    if verbose:\n",
    "        print(\"CREATE RNN FOR GENERATION\")\n",
    "        eddl.summary(unrolled_rnn)\n",
    "        print(f\"Dimensions: visual dim: {visual_dim}, semantic dim: {semantic_dim}, lstm size: {lstm_dim}, n_words: {n_words}\")\n",
    "    #<\n",
    "\n",
    "    cnn_top_in = eddl.Input([visual_dim], name=\"in_visual_features\")\n",
    "    cnn_out_in = eddl.Input([semantic_dim], name=\"in_semantic_features\")\n",
    "    features = eddl.Concat([cnn_top_in, cnn_out_in], name=\"cnn_concat\")  # there is no coattention, name kept for subsequent models\n",
    "    \n",
    "    lstm_in = eddl.Input([n_words])\n",
    "    lstate = eddl.States([2, lstm_dim])\n",
    "    \n",
    "    to_lstm = eddl.ReduceArgMax(lstm_in, [0])  # word index\n",
    "    to_lstm = eddl.Embedding(to_lstm, n_words, 1, word_emb_dim, name=\"word_embs\")\n",
    "    to_lstm = eddl.Concat([to_lstm, features])\n",
    "    lstm = eddl.LSTM([to_lstm, lstate], lstm_dim, True, name=\"lstm_cell\")\n",
    "    lstm.isrecurrent = False\n",
    "    \n",
    "    out_lstm = eddl.Softmax(\n",
    "                eddl.Dense(lstm, n_words, name=\"out_dense\"), \n",
    "                name=\"rnn_out\")\n",
    "    \n",
    "    # *** model\n",
    "    model = eddl.Model([cnn_top_in, cnn_out_in, lstm_in, lstate], [out_lstm])\n",
    "    eddl.build(model, \n",
    "        eddl.adam(lr=1e-04),  # not relevant\n",
    "        [\"binary_cross_entropy\"],  # not relevant\n",
    "        [\"binary_accuracy\"],  # not relevant\n",
    "        get_eddl_cs(config), \n",
    "        init_weights=False)\n",
    "\n",
    "    # if the model is saved in onnx, there is the same error as in the recurrent model when loaded: \n",
    "    #       LDense only works over 2D tensors (LDense)\n",
    "    return model\n",
    "#<\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_predict_next(rnn, n_tokens, visual_batch=None, semantic_batch=None, dev=False):\n",
    "    assert (visual_batch is not None) and (semantic_batch is not None)\n",
    "\n",
    "    bs = visual_batch.shape[0]\n",
    "    lstm = eddl.getLayer(rnn, \"lstm_cell\")\n",
    "    lstm_size = lstm.output.shape[1]\n",
    "    last_layer = eddl.getLayer(rnn, \"rnn_out\")\n",
    "    voc_size = last_layer.output.shape[1]\n",
    "    \n",
    "    # return value\n",
    "    generated_tokens = np.zeros( (bs, n_tokens), dtype=int)\n",
    "\n",
    "    # lstm cell states\n",
    "    state_t = Tensor.zeros([bs, 2, lstm_size])\n",
    "    \n",
    "    # token: input to lstm cell\n",
    "    token = Tensor.zeros([bs, voc_size])\n",
    "    \n",
    "    for j in range(0, n_tokens):\n",
    "        if dev:\n",
    "            print(f\" *** token {j}/{n_tokens} ***\")\n",
    "            print(f\"cnn_visual: {visual_batch.shape}\")\n",
    "            print(f\"cnn_semant: {semantic_batch.shape}\")\n",
    "            print(f\"token: {token.shape}\")\n",
    "            print(f\"state_t: {state_t.shape}\")\n",
    "\n",
    "        # forward: token and state_t update after the forward step\n",
    "        eddl.forward(rnn, [visual_batch, semantic_batch, token, state_t])     \n",
    "        states = eddl.getStates(lstm)\n",
    "\n",
    "        # save the state for the next token: it must be copied into a Tensor (state_t)\n",
    "        for si in range(len(states)):\n",
    "            states[si].reshape_([ states[si].shape[0], 1, states[si].shape[1] ])\n",
    "            state_t.set_select( [\":\", str(si), \":\"] , states[si] )\n",
    "        \n",
    "        out_soft = eddl.getOutput(last_layer)\n",
    "        # pass control to numpy for argmax\n",
    "        wis = np.argmax(out_soft, axis=-1)\n",
    "        # print(wis)\n",
    "        # if dev:\n",
    "        #     print(wis.shape)\n",
    "        #     print(f\"next_token {wis[0]}\")\n",
    "        generated_tokens[:, j] = wis\n",
    "        \n",
    "        #> next input token to the lstm\n",
    "        word_index = Tensor.fromarray(wis.astype(float))\n",
    "        word_index.reshape_([bs, 1])  # add dimension for one-hot encoding\n",
    "        token = Tensor.onehot(word_index, voc_size)\n",
    "        \n",
    "        # print(token.shape)\n",
    "        token.reshape_([bs, voc_size])  # remove singleton dim\n",
    "        #<\n",
    "    #< for n_tokens\n",
    "    return generated_tokens\n",
    "#<\n",
    "\n",
    "\n",
    "class TextGenerator:\n",
    "    def __init__(self, cnn, rnn, dataset, text_dataset, vocab, n_tokens=12, bs=None):\n",
    "        self.cnn = cnn\n",
    "        self.rnn = rnn\n",
    "        self.ds = dataset\n",
    "        self.text_ds = text_dataset\n",
    "        self.vocab = vocab\n",
    "        self.n_tokens = n_tokens\n",
    "        self.bs = bs\n",
    "        \n",
    "    def generate(self, stages=None):\n",
    "        stages = stages or {\n",
    "            # \"train\": ecvl.SplitType.training,\n",
    "            # \"valid\": ecvl.SplitType.validation,\n",
    "            \"test\": ecvl.SplitType.test\n",
    "        }\n",
    "\n",
    "        cnn = self.cnn\n",
    "        cnn_out = eddl.getLayer(cnn, \"cnn_out\")\n",
    "        cnn_top = eddl.getLayer(cnn, \"top\")\n",
    "        \n",
    "        rnn = self.rnn\n",
    "        ds = self.ds\n",
    "        text_ds = self.text_ds\n",
    "        results = {}\n",
    "        \n",
    "        for stage, split_type in stages.items():\n",
    "            gen_sents = []\n",
    "            target_sents = []\n",
    "            print(\"text generation, stage:\", stage)\n",
    "            ds.SetSplit(split_type)\n",
    "            ds.ResetBatch()\n",
    "            ds.Start()\n",
    "            n_batches = ds.GetNumBatches()\n",
    "            t0 = time.perf_counter()\n",
    "            for bi in range(n_batches):\n",
    "                if (bi + 1) % 100 == 0:\n",
    "                    print(f\"batch {bi+1} / {n_batches}\")\n",
    "\n",
    "                I, X, Y = ds.GetBatch()\n",
    "                image_ids = [sample.location_[0] for sample in I]\n",
    "                texts = text_ds.loc[image_ids, \"target_text\"].tolist()\n",
    "                # texts = np.array(texts.tolist()).astype(np.float32)\n",
    "                cnn.forward([X])\n",
    "                cnn_semantic = eddl.getOutput(cnn_out)\n",
    "                cnn_visual = eddl.getOutput(cnn_top)\n",
    "                gen_sentence = generate_text_predict_next(rnn, self.n_tokens, visual_batch=cnn_visual, semantic_batch=cnn_semantic, dev=False)\n",
    "                # gen_s = np.array(gen_sentence)\n",
    "                gen_sents.append(gen_sentence)\n",
    "                target_sents.append(texts)\n",
    "            #< for over batches\n",
    "            t1 = time.perf_counter()\n",
    "            avg_t_batch = (t1 - t0) / n_batches\n",
    "            avg_t_image = avg_t_batch / self.bs if self.bs else {np.NaN}\n",
    "            print(f\"Stage {stage}, all texts generated in {H.precisedelta(t1-t0)}; {H.precisedelta(avg_t_batch)} per {self.bs}-image batch, average time for a single image: {H.precisedelta(avg_t_image)}\")\n",
    "            ds.Stop()\n",
    "            results[stage] = (np.concatenate(gen_sents, axis=0), np.concatenate(target_sents, axis=0))                \n",
    "        #< for over stage\n",
    "        \n",
    "        dfs = [] # stage dfs\n",
    "        def clean(s):\n",
    "            r = []\n",
    "            for w in s:\n",
    "                r.append(w)\n",
    "                if w == Vocabulary.EOS:\n",
    "                    break\n",
    "            return r\n",
    "\n",
    "        for stage, (gen_sents, target_sents) in results.items():\n",
    "            #print(gen_sents.shape)\n",
    "            #print(target_sents.shape)\n",
    "            clean_generated = []\n",
    "            clean_targets = []\n",
    "            for i in range(gen_sents.shape[0]):\n",
    "                ww = np.squeeze(gen_sents[i,:])\n",
    "                tt = np.squeeze(target_sents[i,:])\n",
    "                clean_generated.append(clean(ww))                \n",
    "                clean_targets.append(clean(tt))\n",
    "            df = pd.DataFrame({\"generated_i\": clean_generated, \"target_i\": clean_targets})\n",
    "            df[\"stage\"] = stage\n",
    "            dfs.append(df)\n",
    "        results = pd.concat(dfs, axis=0)\n",
    "        \n",
    "        def decode(tokens):\n",
    "            return \" \".join([self.vocab.idx2word[t] for t in tokens])\n",
    "        \n",
    "        results[\"generated\"] = results.generated_i.apply(decode)\n",
    "        results[\"target\"] = results.target_i.apply(decode)\n",
    "\n",
    "        smoothing_function = SmoothingFunction()\n",
    "        smooth = smoothing_function.method3\n",
    "        \n",
    "\n",
    "        results[\"bleu_1\"] = results[[\"target\", \"generated\"]].apply(lambda x: \n",
    "                sentence_bleu(\n",
    "                        [x[0].split(\" \")], \n",
    "                        x[1].split(\" \"), \n",
    "                        weights=(1, 0, 0, 0), smoothing_function=smooth), axis=1)\n",
    "\n",
    "        #> \n",
    "        def bleu2(target, generated):\n",
    "            target = target.split(\" \")\n",
    "            generated = generated.split(\" \")\n",
    "            score = sentence_bleu([target], generated, weights=(0.5, 0.5, 0, 0), smoothing_function=smooth)\n",
    "            return score\n",
    "        #\n",
    "        results[\"bleu_2\"] = results[[\"target\", \"generated\"]].apply(lambda x: \n",
    "                    bleu2(x[0], x[1]), axis=1)\n",
    "        #<\n",
    "        \n",
    "        results[\"bleu_3\"] = results[[\"target\", \"generated\"]].apply(lambda x: \n",
    "            sentence_bleu(\n",
    "                    [x[0].split(\" \")], \n",
    "                    x[1].split(\" \"), \n",
    "                    weights=(0.33, 0.33, 0.33, 0), smoothing_function=smooth), axis=1)\n",
    "\n",
    "        results[\"bleu_4\"] = results[[\"target\", \"generated\"]].apply(lambda x: \n",
    "            sentence_bleu(\n",
    "                    [x[0].split(\" \")], \n",
    "                    x[1].split(\" \"), \n",
    "                    weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smooth), axis=1)\n",
    "        return results\n",
    "        \n",
    "#<\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:yellow'><font color=\"blue\">\n",
    "GENERATION STARTS HERE\n",
    "</font></span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<span style='background:yellow'><font color=\"blue\">\n",
    "1: GENERATE TEXT ON THE TEST PARTITION AND PRINT THE MEAN BLEU-2 SCORE\n",
    "</font></span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Random Table\n",
      "CS with mid memory setup\n",
      "Building model without initialization\n",
      "Selecting GPU device 0\n",
      "EDDL is running on GPU device 0, Tesla V100-SXM2-32GB\n",
      "CuBlas initialized on GPU device 0, Tesla V100-SXM2-32GB\n",
      "CuRand initialized on GPU device 0, Tesla V100-SXM2-32GB\n",
      "CuDNN initialized on GPU device 0, Tesla V100-SXM2-32GB\n",
      "copying onnx params to devices\n",
      "CS with mid memory setup\n",
      "Building model without initialization\n",
      "copying onnx params to devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset: ecvl_ds.yml\n",
      "using num workers = 8\n",
      "using batch size: 128\n",
      "copy all params from word_embs to word_embs\n",
      "copy all params from lstm_cell to lstm_cell\n",
      "copy all params from out_dense\n",
      " to out_dense\n",
      "text generation, stage: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CS with mid memory setup\n",
      "Building model without initialization\n",
      "copying onnx params to devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "model\n",
      "-------------------------------------------------------------------------------\n",
      "in_visual_features  |  (512)               =>   (512)               0         \n",
      "in_semantic_features|  (46)                =>   (46)                0         \n",
      "cnn_concat          |  (512)               =>   (558)               0         \n",
      "input1              |  (1004)              =>   (1004)              0         \n",
      "reduction_argmax1   |  (1004)              =>   (1)                 0         \n",
      "word_embs           |  (1)                 =>   (512)               514048    \n",
      "concat1             |  (512)               =>   (1070)              0         \n",
      "State1              |  (2, 512)            =>   (2, 512)            0         \n",
      "lstm_cell           |  (1070)              =>   (512)               3241984   \n",
      "out_dense           |  (512)               =>   (1004)              515052    \n",
      "rnn_out             |  (1004)              =>   (1004)              0         \n",
      "-------------------------------------------------------------------------------\n",
      "Total params: 4271084\n",
      "Trainable params: 4271084\n",
      "Non-trainable params: 0\n",
      "\n",
      "Stage test, all texts generated in 8 seconds; 1 second per 128-image batch, average time for a single image: 0 seconds\n",
      "STAGE: test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>generated</th>\n",
       "      <th>bleu_2</th>\n",
       "      <th>stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>&lt;bos&gt; the heart is mildly enlarged &lt;eos&gt;</td>\n",
       "      <td>&lt;bos&gt; the heart is normal in size &lt;eos&gt;</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>&lt;bos&gt; the heart is normal in size &lt;eos&gt;</td>\n",
       "      <td>&lt;bos&gt; the heart is normal in size &lt;eos&gt;</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>&lt;bos&gt; the heart size and pulmonary vascularity...</td>\n",
       "      <td>&lt;bos&gt; the heart size and pulmonary vascularity...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>&lt;bos&gt; there is stable cardiomegaly with xxxx p...</td>\n",
       "      <td>&lt;bos&gt; there is mild cardiomegaly &lt;eos&gt;</td>\n",
       "      <td>0.212395</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>&lt;bos&gt; the heart size and pulmonary vascularity...</td>\n",
       "      <td>&lt;bos&gt; the heart is normal in size &lt;eos&gt;</td>\n",
       "      <td>0.280769</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                target  \\\n",
       "618           <bos> the heart is mildly enlarged <eos>   \n",
       "356            <bos> the heart is normal in size <eos>   \n",
       "715  <bos> the heart size and pulmonary vascularity...   \n",
       "79   <bos> there is stable cardiomegaly with xxxx p...   \n",
       "453  <bos> the heart size and pulmonary vascularity...   \n",
       "\n",
       "                                             generated    bleu_2 stage  \n",
       "618            <bos> the heart is normal in size <eos>  0.517549  test  \n",
       "356            <bos> the heart is normal in size <eos>  1.000000  test  \n",
       "715  <bos> the heart size and pulmonary vascularity...  1.000000  test  \n",
       "79              <bos> there is mild cardiomegaly <eos>  0.212395  test  \n",
       "453            <bos> the heart is normal in size <eos>  0.280769  test  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>generated</th>\n",
       "      <th>bleu_2</th>\n",
       "      <th>stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>&lt;bos&gt; _NUM_ images &lt;eos&gt;</td>\n",
       "      <td>&lt;bos&gt; the heart is normal in size &lt;eos&gt;</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>&lt;bos&gt; the cardiomediastinal silhouette and pul...</td>\n",
       "      <td>&lt;bos&gt; heart size normal &lt;eos&gt;</td>\n",
       "      <td>0.067533</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>&lt;bos&gt; lungs are clear &lt;eos&gt;</td>\n",
       "      <td>&lt;bos&gt; the heart is normal in size and contour ...</td>\n",
       "      <td>0.105409</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>&lt;bos&gt; clear lungs &lt;eos&gt;</td>\n",
       "      <td>&lt;bos&gt; the heart is enlarged &lt;eos&gt;</td>\n",
       "      <td>0.182574</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>&lt;bos&gt; heart size is normal &lt;eos&gt;</td>\n",
       "      <td>&lt;bos&gt; the heart pulmonary xxxx and mediastinum...</td>\n",
       "      <td>0.123091</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                target  \\\n",
       "358                           <bos> _NUM_ images <eos>   \n",
       "721  <bos> the cardiomediastinal silhouette and pul...   \n",
       "521                        <bos> lungs are clear <eos>   \n",
       "340                            <bos> clear lungs <eos>   \n",
       "32                    <bos> heart size is normal <eos>   \n",
       "\n",
       "                                             generated    bleu_2 stage  \n",
       "358            <bos> the heart is normal in size <eos>  0.133631  test  \n",
       "721                      <bos> heart size normal <eos>  0.067533  test  \n",
       "521  <bos> the heart is normal in size and contour ...  0.105409  test  \n",
       "340                  <bos> the heart is enlarged <eos>  0.182574  test  \n",
       "32   <bos> the heart pulmonary xxxx and mediastinum...  0.123091  test  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KPI\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stage</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.257341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bleu_2\n",
       "stage          \n",
       "test   0.257341"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done.\n"
     ]
    }
   ],
   "source": [
    "conf = configure()\n",
    "cnn = load_cnn(conf)\n",
    "vocab = load_vocabulary(conf)\n",
    "trained_rnn = load_rnn(conf)\n",
    "img_text_ds = load_image_text_ds(conf)\n",
    "ecvl_ds = load_ecvl_dataset(conf)\n",
    "# now build non-recurrent version of the recurrent module\n",
    "\n",
    "# dimensions\n",
    "visual_dim = eddl.getLayer(cnn, \"top\").output.shape[1]\n",
    "semantic_dim = eddl.getLayer(cnn, \"cnn_out\").output.shape[1]\n",
    "n_words = len(vocab.idx2word)\n",
    "word_emb_dim = eddl.getLayer(trained_rnn, \"word_embs\").output.shape[1]\n",
    "lstm_dim = eddl.getLayer(trained_rnn, \"lstm_cell\").output.shape[1]\n",
    "\n",
    "# build a non-recurrent RNN with the same weights as the trained RNN\n",
    "rnn = create_rnn_for_generation(trained_rnn, visual_dim, semantic_dim, lstm_dim, n_words, word_emb_dim, conf)\n",
    "\n",
    "# copy weights from unrolled_rnn to rnn\n",
    "layers_to_copy = [ \"word_embs\", \"lstm_cell\", \"out_dense\" ]\n",
    "for l in layers_to_copy:\n",
    "    eddl.copyParam(eddl.getLayer(trained_rnn, l), eddl.getLayer(rnn, l))\n",
    "\n",
    "print(\"\", flush=True)  # simply to keep order of output\n",
    "eddl.set_mode(rnn, 0)\n",
    "eddl.summary(rnn)\n",
    "\n",
    "generator =  TextGenerator(cnn, rnn, ecvl_ds, img_text_ds, vocab, bs=conf[\"bs\"])\n",
    "results = generator.generate()\n",
    "\n",
    "\n",
    "# ALL BLEUs\n",
    "# print(results[[\"bleu_1\", \"bleu_2\", \"bleu_3\", \"bleu_4\", \"stage\"]].groupby(\"stage\").mean())\n",
    "# BLEU-2\n",
    "\n",
    "for stage, df in results[[\"target\", \"generated\", \"bleu_2\", \"stage\"]].groupby(\"stage\"):\n",
    "    print(\"STAGE:\", stage)\n",
    "    display( df[df.bleu_2 > 0.2].sample(5) )\n",
    "    display( df[df.bleu_2 < 0.2].sample(5) )\n",
    "\n",
    "print(\"KPI\")\n",
    "display( results[[\"bleu_2\", \"stage\"]].groupby(\"stage\").mean() )\n",
    "\n",
    "print(\"all done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:yellow'><font color=\"blue\">\n",
    "2: GENERATE TEXT ON SINGLE IMAGES\n",
    "</font></span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CS with mid memory setup\n",
      "Building model without initialization\n",
      "copying onnx params to devices\n",
      "CS with mid memory setup\n",
      "Building model without initialization\n",
      "copying onnx params to devices\n",
      "CS with mid memory setup\n",
      "Building model without initialization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset: ecvl_ds.yml\n",
      "using num workers = 8\n",
      "using batch size: 128\n",
      "copy all params from word_embs to word_embs\n",
      "copy all params from lstm_cell to lstm_cell\n",
      "\n",
      "copy all params from out_dense to out_dense\n",
      "-------------------------------------------------------------------------------\n",
      "model\n",
      "-------------------------------------------------------------------------------\n",
      "in_visual_features  |  (512)               =>   (512)               0         \n",
      "in_semantic_features|  (46)                =>   (46)                0         \n",
      "cnn_concat          |  (512)               =>   (558)               0         \n",
      "input2              |  (1004)              =>   (1004)              0         \n",
      "reduction_argmax2   |  (1004)              =>   (1)                 0         \n",
      "word_embs           |  (1)                 =>   (512)               514048    \n",
      "concat2             |  (512)               =>   (1070)              0         \n",
      "State2              |  (2, 512)            =>   (2, 512)            0         \n",
      "lstm_cell           |  (1070)              =>   (512)               3241984   \n",
      "out_dense           |  (512)               =>   (1004)              515052    \n",
      "rnn_out             |  (1004)              ="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "copying onnx params to devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>enc_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/mnt/datasets/uc5/std-dataset/image/CXR1_1_IM-0001-3001.png</th>\n",
       "      <td>1</td>\n",
       "      <td>the cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>[[5, 62, 39, 9, 55, 19, 7, 21, 13, 66], [15, 6...</td>\n",
       "      <td>[2, 5, 62, 39, 9, 55, 19, 7, 21, 13, 66, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/mnt/datasets/uc5/std-dataset/image/CXR1_1_IM-0001-4001.png</th>\n",
       "      <td>1</td>\n",
       "      <td>the cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>[[5, 62, 39, 9, 55, 19, 7, 21, 13, 66], [15, 6...</td>\n",
       "      <td>[2, 5, 62, 39, 9, 55, 19, 7, 21, 13, 66, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/mnt/datasets/uc5/std-dataset/image/CXR10_IM-0002-1001.png</th>\n",
       "      <td>10</td>\n",
       "      <td>the cardiomediastinal silhouette is within nor...</td>\n",
       "      <td>[[5, 40, 39, 6, 21, 13, 66, 50, 19, 9, 87], [5...</td>\n",
       "      <td>[2, 5, 40, 39, 6, 21, 13, 66, 50, 19, 9, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/mnt/datasets/uc5/std-dataset/image/CXR10_IM-0002-2001.png</th>\n",
       "      <td>10</td>\n",
       "      <td>the cardiomediastinal silhouette is within nor...</td>\n",
       "      <td>[[5, 40, 39, 6, 21, 13, 66, 50, 19, 9, 87], [5...</td>\n",
       "      <td>[2, 5, 40, 39, 6, 21, 13, 66, 50, 19, 9, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/mnt/datasets/uc5/std-dataset/image/CXR100_IM-0002-1001.png</th>\n",
       "      <td>100</td>\n",
       "      <td>both lungs are clear and expanded. heart and m...</td>\n",
       "      <td>[[186, 17, 7, 41, 9, 432], [16, 9, 55, 13], [4...</td>\n",
       "      <td>[2, 186, 17, 7, 41, 9, 432, 3, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id  \\\n",
       "image_filename                                            \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR1_1_IM-0...    1   \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR1_1_IM-0...    1   \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR10_IM-00...   10   \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR10_IM-00...   10   \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR100_IM-0...  100   \n",
       "\n",
       "                                                                                                 text  \\\n",
       "image_filename                                                                                          \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR1_1_IM-0...  the cardiac silhouette and mediastinum size ar...   \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR1_1_IM-0...  the cardiac silhouette and mediastinum size ar...   \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR10_IM-00...  the cardiomediastinal silhouette is within nor...   \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR10_IM-00...  the cardiomediastinal silhouette is within nor...   \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR100_IM-0...  both lungs are clear and expanded. heart and m...   \n",
       "\n",
       "                                                                                             enc_text  \\\n",
       "image_filename                                                                                          \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR1_1_IM-0...  [[5, 62, 39, 9, 55, 19, 7, 21, 13, 66], [15, 6...   \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR1_1_IM-0...  [[5, 62, 39, 9, 55, 19, 7, 21, 13, 66], [15, 6...   \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR10_IM-00...  [[5, 40, 39, 6, 21, 13, 66, 50, 19, 9, 87], [5...   \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR10_IM-00...  [[5, 40, 39, 6, 21, 13, 66, 50, 19, 9, 87], [5...   \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR100_IM-0...  [[186, 17, 7, 41, 9, 432], [16, 9, 55, 13], [4...   \n",
       "\n",
       "                                                                                    target_text  \n",
       "image_filename                                                                                   \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR1_1_IM-0...  [2, 5, 62, 39, 9, 55, 19, 7, 21, 13, 66, 3]  \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR1_1_IM-0...  [2, 5, 62, 39, 9, 55, 19, 7, 21, 13, 66, 3]  \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR10_IM-00...  [2, 5, 40, 39, 6, 21, 13, 66, 50, 19, 9, 3]  \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR10_IM-00...  [2, 5, 40, 39, 6, 21, 13, 66, 50, 19, 9, 3]  \n",
       "/mnt/datasets/uc5/std-dataset/image/CXR100_IM-0...   [2, 186, 17, 7, 41, 9, 432, 3, 0, 0, 0, 0]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">   (1004)              0         \n",
      "-------------------------------------------------------------------------------\n",
      "Total params: 4271084\n",
      "Trainable params: 4271084\n",
      "Non-trainable params: 0\n",
      "\n",
      "* Image 1/5: /mnt/datasets/uc5/std-dataset/image/CXR2086_IM-0717-1001.png: [3, 224, 224]\n",
      "- image annotated in 0.538s\n",
      "- generated word indexes: [ 2  5 16  6 13 22 19  3  0  0  0  0]\n",
      "\tdecoded: <bos> the heart is normal in size <eos> <pad> <pad> <pad> <pad>\n",
      "\tgenerated word indexes cut at EOS: [2, 5, 16, 6, 13, 22, 19, 3]\n",
      "- generated text: <bos> the heart is normal in size <eos>\n",
      "- target text: <bos> the cardiomediastinal silhouette is within normal limits <eos>\n",
      "\n",
      "* Image 2/5: /mnt/datasets/uc5/std-dataset/image/CXR2814_IM-1239-1001.png: [3, 224, 224]\n",
      "- image annotated in 0.085s\n",
      "- generated word indexes: [  2  42  46 111   3   0   0   0   0   0   0   0]\n",
      "\tdecoded: <bos> stable mild cardiomegaly <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\tgenerated word indexes cut at EOS: [2, 42, 46, 111, 3]\n",
      "- generated text: <bos> stable mild cardiomegaly <eos>\n",
      "- target text: <bos> there is cardiomegaly <eos>\n",
      "\n",
      "* Image 3/5: /mnt/datasets/uc5/std-dataset/image/CXR1688_IM-0450-1001.png: [3, 224, 224]\n",
      "- image annotated in 0.067s\n",
      "- generated word indexes: [ 2  5 16  6 13 22 19  9 87  3  0  0]\n",
      "\tdecoded: <bos> the heart is normal in size and contour <eos> <pad> <pad>\n",
      "\tgenerated word indexes cut at EOS: [2, 5, 16, 6, 13, 22, 19, 9, 87, 3]\n",
      "- generated text: <bos> the heart is normal in size and contour <eos>\n",
      "- target text: <bos> heart size is normal and cardiomediastinal contours are normal <eos>\n",
      "\n",
      "* Image 4/5: /mnt/datasets/uc5/std-dataset/image/CXR2655_IM-1137-2001.png: [3, 224, 224]\n",
      "- image annotated in 0.103s\n",
      "- generated word indexes: [ 2  5 16  6 13 22 19  3  0  0  0  0]\n",
      "\tdecoded: <bos> the heart is normal in size <eos> <pad> <pad> <pad> <pad>\n",
      "\tgenerated word indexes cut at EOS: [2, 5, 16, 6, 13, 22, 19, 3]\n",
      "- generated text: <bos> the heart is normal in size <eos>\n",
      "- target text: <bos> the cardiomediastinal silhouette is normal in size in appearance and <eos>\n",
      "\n",
      "* Image 5/5: /mnt/datasets/uc5/std-dataset/image/CXR1721_IM-0476-2001.png: [3, 224, 224]\n",
      "- image annotated in 0.075s\n",
      "- generated word indexes: [ 2  5 16 19  9 20 73 64 21 13 66  3]\n",
      "\tdecoded: <bos> the heart size and pulmonary vascularity appear within normal limits <eos>\n",
      "\tgenerated word indexes cut at EOS: [2, 5, 16, 19, 9, 20, 73, 64, 21, 13, 66, 3]\n",
      "- generated text: <bos> the heart size and pulmonary vascularity appear within normal limits <eos>\n",
      "- target text: <bos> the heart pulmonary xxxx and mediastinum are within normal limits <eos>\n",
      "\n",
      "all done.\n"
     ]
    }
   ],
   "source": [
    "conf = configure()\n",
    "cnn = load_cnn(conf)\n",
    "vocab = load_vocabulary(conf)\n",
    "trained_rnn = load_rnn(conf)\n",
    "img_text_ds = load_image_text_ds(conf)\n",
    "ecvl_ds = load_ecvl_dataset(conf)\n",
    "# now build non-recurrent version of the recurrent module\n",
    "\n",
    "# dimensions\n",
    "visual_dim = eddl.getLayer(cnn, \"top\").output.shape[1]\n",
    "semantic_dim = eddl.getLayer(cnn, \"cnn_out\").output.shape[1]\n",
    "n_words = len(vocab.idx2word)\n",
    "word_emb_dim = eddl.getLayer(trained_rnn, \"word_embs\").output.shape[1]\n",
    "lstm_dim = eddl.getLayer(trained_rnn, \"lstm_cell\").output.shape[1]\n",
    "\n",
    "# build a non-recurrent RNN with the same weights as the trained RNN\n",
    "rnn = create_rnn_for_generation(trained_rnn, visual_dim, semantic_dim, lstm_dim, n_words, word_emb_dim, conf)\n",
    "\n",
    "# copy weights from unrolled_rnn to rnn\n",
    "layers_to_copy = [ \"word_embs\", \"lstm_cell\", \"out_dense\" ]\n",
    "for l in layers_to_copy:\n",
    "    eddl.copyParam(eddl.getLayer(trained_rnn, l), eddl.getLayer(rnn, l))\n",
    "eddl.set_mode(rnn, 0)\n",
    "\n",
    "\n",
    "print(\"\", flush=True)  # simply to keep order of output\n",
    "eddl.summary(rnn)\n",
    "\n",
    "#\n",
    "# -----------------------------------------------------\n",
    "#\n",
    "\n",
    "\n",
    "_, augs = get_augmentations_chest_iu()\n",
    "filenames = [\"CXR2086_IM-0717-1001.png\", \"CXR2814_IM-1239-1001.png\", \"CXR1688_IM-0450-1001.png\", \"CXR2655_IM-1137-2001.png\", \"CXR1721_IM-0476-2001.png\"]\n",
    "# filenames = [join(conf[\"img_fld\"], fn) for fn in filenames]\n",
    "filenames = [join(\"./images\", fn) for fn in filenames]\n",
    "\n",
    "cnn_out = eddl.getLayer(cnn, \"cnn_out\")\n",
    "cnn_top = eddl.getLayer(cnn, \"top\")\n",
    "\n",
    "# cut the generated text at EOS\n",
    "def clean(s):\n",
    "    r = []\n",
    "    for w in s:\n",
    "        r.append(w)\n",
    "        if w == Vocabulary.EOS:\n",
    "            break\n",
    "    return r\n",
    "\n",
    "def decode(wis):\n",
    "    return \" \".join([vocab.idx2word[word_index] for word_index in wis])\n",
    "\n",
    "display(img_text_ds.head())\n",
    "\n",
    "for i, fn in enumerate(filenames):\n",
    "    t0 = time.perf_counter()\n",
    "    # read image from disk\n",
    "    img = ecvl.ImRead(fn)  # , flags=ecvl.ImReadMode.GRAYSCALE)\n",
    "    augs.Apply(img)\n",
    "    ecvl.RearrangeChannels(img, img, \"cxy\")\n",
    "    print(f\"* Image {i+1}/{len(filenames)}: {fn}: {img.dims_}\")\n",
    "    img = np.array(img, copy=False)\n",
    "    \n",
    "    # resize and create Tensor\n",
    "    img = np.expand_dims(img, 0)  # add \"batch\" dimension\n",
    "    img = Tensor(img)\n",
    "    \n",
    "    # forward through CNN\n",
    "    cnn.forward([img])\n",
    "    cnn_semantic = eddl.getOutput(cnn_out)\n",
    "    cnn_visual = eddl.getOutput(cnn_top)\n",
    "    \n",
    "    # generate text\n",
    "    word_indexes = generate_text_predict_next(rnn, conf[\"n_tokens\"], cnn_visual, cnn_semantic)[0]\n",
    "    t1 = time.perf_counter()\n",
    "    print(f\"- image annotated in {t1-t0:.3f}s\")\n",
    "    print(\"- generated word indexes:\", word_indexes)\n",
    "    text = decode(word_indexes)\n",
    "    print(\"\\tdecoded:\", text)\n",
    "    # clean generated text: remove word indexes after EOS\n",
    "    word_indexes = clean(word_indexes)\n",
    "    print(\"\\tgenerated word indexes cut at EOS:\", word_indexes)\n",
    "    text = decode(word_indexes)\n",
    "    print(\"- generated text:\", text)\n",
    "    # target text\n",
    "    target_word_indexes = img_text_ds.loc[fn, \"target_text\"]\n",
    "    target_text = decode(clean(target_word_indexes))\n",
    "    print(\"- target text:\", target_text)\n",
    "    print()\n",
    "\n",
    "print(\"all done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('eddl2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c36fb492bbd491e41529af2aec597382d07c9f2ffbc3911cd67d485cde204aba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
